{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import shap\n",
    "import os\n",
    "import sys\n",
    "import joblib\n",
    "from pathlib import Path\n",
    "\n",
    "# Machine learning libraries\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV, ParameterGrid\n",
    "from imblearn.pipeline import Pipeline\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "\n",
    "\n",
    "# Add the src directory to Python path to import our utils module\n",
    "src_path = os.path.abspath(\"../../src\")\n",
    "if src_path not in sys.path:\n",
    "    sys.path.append(src_path)\n",
    "\n",
    "# Import feature engineering utilities from our custom module\n",
    "from project_utils import (  # type: ignore\n",
    "    confusion_matrix_analysis,\n",
    ")\n",
    "\n",
    "# Metrics\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    classification_report, confusion_matrix, \n",
    "    precision_recall_curve\n",
    ")\n",
    "\n",
    "\n",
    "# Styling\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# Display options\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "print(\"📚 Libraries imported successfully!\")\n",
    "print(f\"📍 Working directory: {os.getcwd()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load preprocessed data\n",
    "print(\"LOADING PREPROCESSED DATA:\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Define data paths\n",
    "data_path = \"../../data/processed\"\n",
    "X_file = os.path.join(data_path, \"X_features.csv\")\n",
    "y_file = os.path.join(data_path, \"y_target.csv\")\n",
    "\n",
    "# Load features and target\n",
    "X = pd.read_csv(X_file)\n",
    "y = pd.read_csv(y_file).squeeze()  # Convert to Series\n",
    "\n",
    "print(f\"✅ Features loaded: {X.shape}\")\n",
    "print(f\"✅ Target loaded: {y.shape}\")\n",
    "\n",
    "print(f\"\\n📊 Dataset Summary:\")\n",
    "print(f\"   Total samples: {len(X)}\")\n",
    "print(f\"   Total features: {X.shape[1]}\")\n",
    "print(f\"   Target variable: {y.name}\")\n",
    "print(f\"   Target classes: {sorted(y.unique())}\")\n",
    "print(f\"   Class distribution:\")\n",
    "for class_val in sorted(y.unique()):\n",
    "    count = (y == class_val).sum()\n",
    "    percentage = (count / len(y)) * 100\n",
    "    print(f\"     Class {class_val}: {count} ({percentage:.1f}%)\")\n",
    "\n",
    "print(f\"\\n🎯 Data ready for modeling!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.columns.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "## 2. Train/Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create train/test split\n",
    "print(\"TRAIN/TEST SPLIT:\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Split with stratification to maintain class balance\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, \n",
    "    test_size=0.2, \n",
    "    random_state=42, \n",
    "    stratify=y\n",
    ")\n",
    "\n",
    "print(f\"✅ Train set: {X_train.shape}\")\n",
    "print(f\"✅ Test set: {X_test.shape}\")\n",
    "\n",
    "print(f\"\\n📊 Class distribution after split:\")\n",
    "print(f\"\\nTraining set:\")\n",
    "for class_val in sorted(y_train.unique()):\n",
    "    count = (y_train == class_val).sum()\n",
    "    percentage = (count / len(y_train)) * 100\n",
    "    print(f\"  Class {class_val}: {count} ({percentage:.1f}%)\")\n",
    "\n",
    "print(f\"\\nTest set:\")\n",
    "for class_val in sorted(y_test.unique()):\n",
    "    count = (y_test == class_val).sum()\n",
    "    percentage = (count / len(y_test)) * 100\n",
    "    print(f\"  Class {class_val}: {count} ({percentage:.1f}%)\")\n",
    "\n",
    "print(f\"\\n🎯 Stratified split completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# ================================\n",
    "# Create Pipeline and CV Strategy\n",
    "# ================================\n",
    "# Create a pipeline with RandomForest\n",
    "pipeline = Pipeline([\n",
    "    ('smote', SMOTE(random_state=42)),\n",
    "    ('rf', RandomForestClassifier(random_state=42, n_jobs=-1))\n",
    "])\n",
    "\n",
    "# Define cross-validation strategy\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# ================================\n",
    "# Paramètres à tester pour GridSearch\n",
    "# ================================\n",
    "param_grid = {\n",
    "    \"rf__n_estimators\": [200, 300, 400],\n",
    "    \"rf__max_depth\": [6, 7, 8],\n",
    "    \"rf__min_samples_split\": [4, 8, 12],\n",
    "    \"rf__min_samples_leaf\": [2, 4, 6],\n",
    "    \"rf__max_features\": [\"sqrt\", \"log2\"],\n",
    "    \"rf__class_weight\": [None, \"balanced\", \"balanced_subsample\"]\n",
    "}\n",
    "\n",
    "print(\"🔍 GridSearchCV Configuration:\")\n",
    "print(f\"   Pipeline steps: {list(pipeline.named_steps.keys())}\")\n",
    "print(f\"   CV strategy: {cv}\")\n",
    "print(f\"   Parameter combinations: {len(list(ParameterGrid(param_grid)))}\")\n",
    "print(f\"   Scoring metric: recall\")\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=pipeline,\n",
    "    param_grid=param_grid,\n",
    "    scoring=\"recall\", \n",
    "    cv=cv,\n",
    "    n_jobs=-1,\n",
    "    verbose=1,\n",
    ")\n",
    "\n",
    "print(\"\\n🚀 Starting GridSearchCV...\")\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"✅ Meilleurs paramètres trouvés :\")\n",
    "print(grid_search.best_params_)\n",
    "print(f\"Meilleur Recall (CV): {grid_search.best_score_:.4f}\")\n",
    "\n",
    "print(f\"\\n📋 GridSearchCV terminé. Évaluation finale avec seuil optimal dans la cellule suivante...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =======================\n",
    "# SEUIL OPTIMAL + ÉVALUATION FINALE\n",
    "# =======================\n",
    "\n",
    "# Probabilités de la classe 1\n",
    "y_proba_test = grid_search.best_estimator_.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Courbe précision-rappel\n",
    "precision, recall, thresholds = precision_recall_curve(y_test, y_proba_test)\n",
    "\n",
    "# Calcul du F1-score pour chaque seuil\n",
    "f1_scores = 2 * (precision * recall) / (precision + recall + 1e-8)\n",
    "\n",
    "# --- Option B : viser un rappel minimal avec meilleure précision possible ---\n",
    "target_recall = 0.80  # à ajuster selon ton objectif\n",
    "idxs = np.where(recall >= target_recall)[0]\n",
    "\n",
    "if len(idxs):\n",
    "    # parmi les seuils qui atteignent le rappel cible, on prend celui avec la meilleure précision\n",
    "    optimal_idx = idxs[np.argmax(precision[idxs])]\n",
    "else:\n",
    "    # si aucun seuil ne dépasse le rappel cible, fallback : seuil max F1\n",
    "    optimal_idx = np.argmax(f1_scores)\n",
    "\n",
    "optimal_threshold = thresholds[optimal_idx]\n",
    "print(f\"🔹 Optimal threshold: {optimal_threshold:.3f}\")\n",
    "print(\n",
    "    f\"➡️ Recall atteint : {recall[optimal_idx]:.3f} | Precision : {precision[optimal_idx]:.3f}\"\n",
    ")\n",
    "\n",
    "# Visualiser la courbe Precision-Recall\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(recall, precision, color=\"blue\", lw=2)\n",
    "\n",
    "# Marquer le point du seuil optimal\n",
    "plt.scatter(recall[optimal_idx], precision[optimal_idx], color=\"red\", s=100, zorder=5)\n",
    "plt.text(\n",
    "    recall[optimal_idx] + 0.02,\n",
    "    precision[optimal_idx] - 0.02,\n",
    "    f\"Threshold={optimal_threshold:.3f}\",\n",
    "    color=\"red\",\n",
    "    fontsize=12,\n",
    ")\n",
    "\n",
    "plt.xlabel(\"Recall\")\n",
    "plt.ylabel(\"Precision\")\n",
    "plt.title(\"Precision-Recall Curve\")\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Appliquer le seuil pour créer les prédictions finales\n",
    "y_pred_final = (y_proba_test >= optimal_threshold).astype(int)\n",
    "\n",
    "# Évaluation finale sur le test set\n",
    "accuracy_test = accuracy_score(y_test, y_pred_final)\n",
    "precision_test = precision_score(y_test, y_pred_final, average=\"weighted\", zero_division=0)\n",
    "recall_test = recall_score(y_test, y_pred_final, average=\"weighted\")\n",
    "f1_test = f1_score(y_test, y_pred_final, average=\"weighted\")\n",
    "\n",
    "print(f\"\\n📊 Test Set Performance (avec seuil choisi):\")\n",
    "print(f\"Accuracy : {accuracy_test:.4f}\")\n",
    "print(f\"Precision: {precision_test:.4f}\")\n",
    "print(f\"Recall   : {recall_test:.4f}\")\n",
    "print(f\"F1-Score : {f1_test:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =======================\n",
    "# RAPPORT DÉTAILLÉ DU MODÈLE\n",
    "# =======================\n",
    "\n",
    "# Classification report détaillé\n",
    "print(\"📋 Classification Report:\")\n",
    "print(\"=\"*50)\n",
    "print(classification_report(y_test, y_pred_final))\n",
    "\n",
    "# Confusion matrix avec visualisation\n",
    "confusion_matrix_analysis(\n",
    "    y_test, y_pred_final, model_name=\"Random Forest Optimisé\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importance\n",
    "feature_importance = pd.DataFrame(\n",
    "    {\n",
    "        \"feature\": X.columns,\n",
    "        \"importance\": grid_search.best_estimator_.named_steps[\n",
    "            \"rf\"\n",
    "        ].feature_importances_,\n",
    "    }\n",
    ").sort_values(\"importance\", ascending=False)\n",
    "\n",
    "print(\"\\n🔍 Top 10 Most Important Features:\")\n",
    "for i, (_, row) in enumerate(feature_importance.head(10).iterrows()):\n",
    "    print(f\"   {i+1:2d}. {row['feature']:<25} : {row['importance']:.4f}\")\n",
    "\n",
    "# ================================\n",
    "# FEATURE IMPORTANCE VISUALIZATION\n",
    "# ================================\n",
    "print(\"\\n📊 Feature Importance Visualization:\")\n",
    "\n",
    "# Calculate percentages\n",
    "top_features = feature_importance.head(15)\n",
    "top_features_percentage = (top_features['importance'] * 100).round(1)\n",
    "\n",
    "# Simple horizontal bar chart\n",
    "plt.figure(figsize=(14, 8))\n",
    "\n",
    "# Create horizontal bar chart\n",
    "bars = plt.barh(range(len(top_features)), top_features['importance'], \n",
    "                color='steelblue', alpha=0.8)\n",
    "\n",
    "# Customize the chart\n",
    "plt.yticks(range(len(top_features)), top_features['feature'])\n",
    "plt.xlabel('Feature Importance', fontsize=12)\n",
    "plt.title('Top 15 Feature Importance (Random Forest)', fontsize=14, fontweight='bold')\n",
    "plt.grid(axis='x', alpha=0.3)\n",
    "\n",
    "# Add value labels on bars with percentages only\n",
    "for i, (bar, percentage) in enumerate(zip(bars, top_features_percentage)):\n",
    "    plt.text(bar.get_width() + 0.001, bar.get_y() + bar.get_height()/2, \n",
    "             f'{percentage}%', va='center', fontsize=11, fontweight='bold')\n",
    "\n",
    "# Add cumulative percentage text box\n",
    "cumulative_percentage = top_features_percentage.sum()\n",
    "textstr = f'Top 15 features represent:\\n{cumulative_percentage:.1f}% of total importance'\n",
    "props = dict(boxstyle='round', facecolor='lightblue', alpha=0.8)\n",
    "plt.text(0.02, 0.98, textstr, transform=plt.gca().transAxes, fontsize=11,\n",
    "         verticalalignment='top', bbox=props)\n",
    "\n",
    "# Invert y-axis to have most important at top\n",
    "plt.gca().invert_yaxis()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print summary statistics\n",
    "print(f\"\\n📈 Feature Importance Summary:\")\n",
    "print(f\"   Top 15 features contribute: {cumulative_percentage:.1f}% of total importance\")\n",
    "print(f\"   Top 5 features contribute: {top_features_percentage.head(5).sum():.1f}% of total importance\")\n",
    "print(f\"   Most important feature: {top_features.iloc[0]['feature']} ({top_features_percentage.iloc[0]:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "## 3. Model Explainability with SHAP\n",
    "\n",
    "Understanding model predictions through SHAP (SHapley Additive exPlanations) analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =======================\n",
    "# SHAP ANALYSIS - MODEL EXPLAINABILITY\n",
    "# =======================\n",
    "\n",
    "# Initialize SHAP explainer for RandomForest\n",
    "print(\"🔍 Initializing SHAP TreeExplainer...\")\n",
    "rf_model = grid_search.best_estimator_.named_steps['rf']\n",
    "explainer = shap.TreeExplainer(rf_model)\n",
    "\n",
    "# Calculate SHAP values for test set (use subset for performance)\n",
    "print(\"📊 Calculating SHAP values for test set...\")\n",
    "n_samples_shap = min(100, len(X_test))  # Limit to 100 samples for performance\n",
    "X_test_sample = X_test.iloc[:n_samples_shap]\n",
    "shap_values = explainer.shap_values(X_test_sample)\n",
    "\n",
    "print(f\"✅ SHAP values calculated for {n_samples_shap} samples\")\n",
    "print(f\"📐 SHAP values shape: {shap_values.shape if not isinstance(shap_values, list) else [sv.shape for sv in shap_values]}\")\n",
    "\n",
    "# Handle different SHAP output formats\n",
    "if isinstance(shap_values, list):\n",
    "    # Multi-class case: take class 1 (employees who left)\n",
    "    shap_values_class1 = shap_values[1]\n",
    "    expected_value = float(explainer.expected_value[1])\n",
    "else:\n",
    "    # Check if shap_values has 3 dimensions (samples, features, classes)\n",
    "    if len(shap_values.shape) == 3:\n",
    "        # Take the second class (class 1 - employees who left)\n",
    "        shap_values_class1 = shap_values[:, :, 1]\n",
    "        expected_value = float(explainer.expected_value[1] if isinstance(explainer.expected_value, np.ndarray) else explainer.expected_value)\n",
    "    else:\n",
    "        # Binary case: shap_values is already for positive class\n",
    "        shap_values_class1 = shap_values\n",
    "        expected_value = float(explainer.expected_value if isinstance(explainer.expected_value, np.ndarray) else explainer.expected_value)\n",
    "\n",
    "print(f\"📐 Final SHAP values shape: {shap_values_class1.shape}\")\n",
    "print(f\"🎯 Expected value: {expected_value:.4f}\")\n",
    "\n",
    "# 1. Summary Plot - Global feature importance\n",
    "print(\"\\n📈 1. SHAP Summary Plot (Global Importance):\")\n",
    "plt.figure(figsize=(12, 8))\n",
    "shap.summary_plot(shap_values_class1, X_test_sample, show=False)\n",
    "plt.title(\"SHAP Summary Plot - Feature Impact on Employee Turnover\", fontsize=14, pad=20)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 2. Feature Importance Bar Plot\n",
    "print(\"\\n📊 2. SHAP Feature Importance (Mean Absolute Values):\")\n",
    "plt.figure(figsize=(12, 8))\n",
    "shap.summary_plot(shap_values_class1, X_test_sample, plot_type=\"bar\", show=False)\n",
    "plt.title(\"SHAP Feature Importance - Employee Turnover Prediction\", fontsize=14, pad=20)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 3. Waterfall plot for first prediction\n",
    "print(\"\\n💧 3. SHAP Waterfall Plot (Individual Prediction Example):\")\n",
    "\n",
    "\n",
    "# 🟢 Trouver les employés prédits comme \"départ\"\n",
    "rf_pipeline = grid_search.best_estimator_\n",
    "y_pred_proba = rf_pipeline.predict_proba(X_test_sample)[:, 1]\n",
    "y_pred_class = (y_pred_proba >= 0.5).astype(int)\n",
    "\n",
    "indices_depart = np.where(y_pred_class == 1)[0]\n",
    "\n",
    "if len(indices_depart) == 0:\n",
    "    print(\"⚠️ Aucun employé prédit comme 'départ' dans l'échantillon SHAP.\")\n",
    "    example_idx = 0  # fallback\n",
    "else:\n",
    "    # Trier les employés 'départ' par probabilité décroissante\n",
    "    top_depart_idx = np.argsort(y_pred_proba[indices_depart])[::-1]\n",
    "    example_idx = indices_depart[top_depart_idx[1]]\n",
    "\n",
    "print(\n",
    "    f\"🎯 Employé choisi : index {example_idx} | proba départ = {y_pred_proba[example_idx]:.3f}\"\n",
    ")\n",
    "\n",
    "try:\n",
    "    # Create SHAP Explanation object for waterfall plot\n",
    "    explanation = shap.Explanation(\n",
    "        values=shap_values_class1[example_idx], \n",
    "        base_values=expected_value, \n",
    "        data=X_test_sample.iloc[example_idx].values,\n",
    "        feature_names=X_test_sample.columns.tolist()\n",
    "    )\n",
    "    \n",
    "    # Create waterfall plot\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    shap.plots.waterfall(explanation, show=False)\n",
    "    plt.title(f\"SHAP Waterfall Plot - Employee {example_idx} Prediction Breakdown\", fontsize=14, pad=20)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"⚠️ Waterfall plot not available: {e}\")\n",
    "    # Alternative: show values as text\n",
    "    print(\"Individual prediction breakdown:\")\n",
    "    shap_values_single = shap_values_class1[example_idx]\n",
    "    \n",
    "    # Create feature-value pairs and sort by absolute importance\n",
    "    feature_contributions = []\n",
    "    for feature, value in zip(X_test_sample.columns, shap_values_single):\n",
    "        # Convert to float safely\n",
    "        if isinstance(value, np.ndarray):\n",
    "            actual_value = float(value.item() if value.size == 1 else np.mean(value))\n",
    "        else:\n",
    "            actual_value = float(value)\n",
    "        \n",
    "        if abs(actual_value) > 0.01:  # Only show significant contributions\n",
    "            feature_contributions.append((feature, actual_value))\n",
    "    \n",
    "    # Sort by absolute contribution\n",
    "    feature_contributions.sort(key=lambda x: abs(x[1]), reverse=True)\n",
    "    \n",
    "    print(f\"   Base value: {expected_value:.4f}\")\n",
    "    for feature, value in feature_contributions[:10]:  # Show top 10\n",
    "        direction = \"increases\" if value > 0 else \"decreases\"\n",
    "        print(f\"   {feature:<25}: {value:+.4f} ({direction} turnover probability)\")\n",
    "\n",
    "# 4. Top SHAP feature insights\n",
    "print(\"\\n🎯 4. SHAP Insights Summary:\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Calculate mean absolute SHAP values for feature ranking\n",
    "mean_abs_shap = np.abs(shap_values_class1).mean(axis=0)\n",
    "feature_importance_shap = pd.DataFrame({\n",
    "    'feature': X_test_sample.columns,\n",
    "    'mean_abs_shap': mean_abs_shap\n",
    "}).sort_values('mean_abs_shap', ascending=False)\n",
    "\n",
    "print(\"🔍 Top 10 Most Influential Features (SHAP):\")\n",
    "for i, (_, row) in enumerate(feature_importance_shap.head(10).iterrows()):\n",
    "    print(f\"   {i+1:2d}. {row['feature']:<25} : {row['mean_abs_shap']:.4f}\")\n",
    "\n",
    "# Compare with Random Forest feature importance\n",
    "print(\"\\n📋 SHAP vs Random Forest Importance Comparison:\")\n",
    "print(\"-\" * 60)\n",
    "rf_importance = pd.DataFrame({\n",
    "    'feature': X.columns,\n",
    "    'rf_importance': rf_model.feature_importances_\n",
    "}).sort_values('rf_importance', ascending=False)\n",
    "\n",
    "# Top 5 comparison\n",
    "print(\"Top 5 Features Comparison:\")\n",
    "print(f\"{'Rank':<5} {'SHAP Feature':<25} {'RF Feature':<25}\")\n",
    "print(\"-\" * 60)\n",
    "for i in range(5):\n",
    "    shap_feat = feature_importance_shap.iloc[i]['feature']\n",
    "    rf_feat = rf_importance.iloc[i]['feature']\n",
    "    print(f\"{i+1:<5} {shap_feat:<25} {rf_feat:<25}\")\n",
    "\n",
    "print(f\"\\n✅ SHAP Analysis Complete!\")\n",
    "print(\"💡 Key Insights:\")\n",
    "print(\"   - SHAP values show individual prediction contributions\")\n",
    "print(\"   - Red dots = increase probability of leaving\")\n",
    "print(\"   - Blue dots = decrease probability of leaving\") \n",
    "print(\"   - Use these insights to understand model decisions and improve retention strategies\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Calculer la distance entre la prédiction et la base value\n",
    "shap_sum = shap_values_class1.sum(axis=1)  # somme des SHAP par observation\n",
    "pred_diff = shap_sum  # distance à la valeur attendue (expected_value)\n",
    "# Optionnel : on peut aussi regarder les extrêmes de probabilité\n",
    "# pred_diff = y_proba_test - expected_value\n",
    "\n",
    "# 2. Sélectionner les top N observations \"intéressantes\"\n",
    "N = 5\n",
    "top_indices = np.argsort(np.abs(pred_diff))[-N:]  # N plus impactantes\n",
    "\n",
    "# 3. Afficher les indices et la probabilité\n",
    "print(\"🔹 Top examples pour Waterfall Plot:\")\n",
    "for idx in top_indices:\n",
    "    print(\n",
    "        f\"Index {idx} - Probabilité départ: {y_proba_test[idx]:.3f}, SHAP sum: {shap_sum[idx]:.3f}\"\n",
    "    )\n",
    "\n",
    "# 4. Exemple pour tracer un waterfall sur le top 1\n",
    "example_idx = top_indices[2]\n",
    "\n",
    "explanation = shap.Explanation(\n",
    "    values=shap_values_class1[example_idx],\n",
    "    base_values=expected_value,\n",
    "    data=X_test_sample.iloc[example_idx].values,\n",
    "    feature_names=X_test_sample.columns.tolist(),\n",
    ")\n",
    "\n",
    "shap.plots.waterfall(explanation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the best model\n",
    "\n",
    "model_dir = Path(\"../../models\")\n",
    "model_dir.mkdir(parents=True, exist_ok=True)\n",
    "model_path = model_dir / \"random_forest_optimized.pkl\"\n",
    "joblib.dump(grid_search.best_estimator_, model_path)\n",
    "print(f\"✅ Best model saved to {model_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "oc-p4-esn-technova-partners",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
